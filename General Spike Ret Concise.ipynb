{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea64659e-f244-4805-96ff-1d2a70e0d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91aaf07-db00-427f-961c-10ae4a144e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'site_coordinates',\n",
       " 'stim_indices',\n",
       " 'trial_params',\n",
       " 'trial_params_short']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters, load data\n",
    "year = '2024'\n",
    "month = '12'\n",
    "day = '05'\n",
    "\n",
    "monkey = 'Bourgeois'\n",
    "\n",
    "start_bin = -.1\n",
    "end_bin = .301\n",
    "blank_or_nonblank = 'blank'\n",
    "\n",
    "pathname = f'/Users/parsatalaie/Desktop/Marmoset Datasets/{year}{month}{day}_all_psth.h5'\n",
    "\n",
    "f = h5py.File(pathname)\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc28700-8de9-4484-b288-1de9032b6d68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/parsatalaie/Desktop/Marmoset Data Analysis', '/opt/anaconda3/lib/python312.zip', '/opt/anaconda3/lib/python3.12', '/opt/anaconda3/lib/python3.12/lib-dynload', '', '/opt/anaconda3/lib/python3.12/site-packages', '/opt/anaconda3/lib/python3.12/site-packages/aeosa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parsatalaie/Desktop/Issa Data/data_analysis_tools_mkTurk/general.py:23: UserWarning: Failed to import analysis_metadata module.\n",
      "  warnings.warn('Failed to import analysis_metadata module.')\n",
      "/Users/parsatalaie/Desktop/Issa Data/data_analysis_tools_mkTurk/IO.py:21: UserWarning: Failed to import analysis_metadata module.\n",
      "  warnings.warn('Failed to import analysis_metadata module.')\n"
     ]
    }
   ],
   "source": [
    "# Add path to and import mkturk analysis tools\n",
    "\n",
    "from sys import path\n",
    "\n",
    "print(path)\n",
    "\n",
    "path.append('/Users/parsatalaie/Desktop/Issa Data')\n",
    "\n",
    "from data_analysis_tools_mkTurk.utils_meta import get_recording_path\n",
    "from data_analysis_tools_mkTurk.general import df_2_psth_mat\n",
    "from data_analysis_tools_mkTurk.IO import ch_dicts_2_h5, h5_2_trial_df, h5_2_df\n",
    "from data_analysis_tools_mkTurk.npix import chs_meta_2_site_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c74fc8-f578-4f73-a7e8-01e7222bcaea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tables/attributeset.py:290: DataTypeWarning: Unsupported type for attribute 'scenefile_by_stim_mat' in node '/'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    }
   ],
   "source": [
    "# Create, print trial_params\n",
    "\n",
    "trial_params = h5_2_trial_df(pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd8cf4e-ed81-41c1-aa63-e0335962d1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/mkturkfiles/scenebags/West/BlankStim_300ms.json',\n",
       "       '/mkturkfiles/scenebags/West/neural_stim_4_0ABCDEFGHIJ.json',\n",
       "       '/mkturkfiles/scenebags/West/20231025_Rust_NaturalImages300_300ms.json',\n",
       "       '/mkturkfiles/scenebags/West/20231025_Var6vbslir_set0_im151_neptune_dur300ms_lab_updated.json',\n",
       "       '/mkturkfiles/scenebags/West/20231025_Var6vbslir_set0_im151_elias_dur300ms_lab_updated.json'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List scenefiles\n",
    "\n",
    "trial_params['scenefile'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f6125c-3b09-45fc-b036-096b573203c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rust\n",
    "scenefiles = ['/mkturkfiles/scenebags/West/20231025_Rust_NaturalImages300_300ms.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93b69834-c96a-4544-b186-a4d295ccd272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objaverse\n",
    "scenefiles = ['/mkturkfiles/scenebags/West/neural_stim_4_0ABCDEFGHIJ.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c57fbc3b-06fc-415e-ac93-38bc93342896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elias/Neptune\n",
    "scenefiles = ['/mkturkfiles/scenebags/West/20231025_Var6vbslir_set0_im151_neptune_dur300ms_lab_updated.json',\n",
    "       '/mkturkfiles/scenebags/West/20231025_Var6vbslir_set0_im151_elias_dur300ms_lab_updated.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04ecb07-bae9-4669-9e60-3a4d9b3b9890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HvM\n",
    "scenefiles = ['/mkturkfiles/scenebags/West/hvm10_table_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_elephant_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_dog_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_bear_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_chair_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_car_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_turtle_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_plane_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_apple_45_20240906.json',\n",
    "       '/mkturkfiles/scenebags/West/hvm10_head_45_20240906.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c0db365-32ac-4854-8456-1813cd80168c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching trial parameters...\n",
      "... done (0.02726292610168457 sec).\n",
      "inds_df.shape = (4500, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tables/attributeset.py:290: DataTypeWarning: Unsupported type for attribute 'scenefile_by_stim_mat' in node '/'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-fetching PSTHs from HDF5...\n",
      "... done.\n",
      "Duration=0.008544254302978515 minutes\n",
      "Fancy slicing numpy array...\n",
      "... done.\n",
      "Duration=0.008700851599375408 minutes\n"
     ]
    }
   ],
   "source": [
    "# Select stimulus presentations associated with requested scenefiles:\n",
    "filter = trial_params.scenefile.isin(scenefiles)\n",
    "rust_trials = trial_params[filter]\n",
    "array_filter = np.array(rust_trials[['trial_num', 'rsvp_num']])\n",
    "\n",
    "# Read spike count data from HDF5 for requested trials:\n",
    "time_window = [start_bin, end_bin] # Beginning and end of peristimulus time window for each stim, relative to trigger in seconds\n",
    "rust_data = h5_2_df(pathname, trials=array_filter, time_window=time_window)\n",
    "\n",
    "# Sort rust_data to match trial_params, rust_trials\n",
    "rust_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2518320c-65f7-42d5-aeb0-806f7105ced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3747, 12)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create + apply mask to remove nans\n",
    "mask = rust_data.apply(lambda x : np.all(np.isnan(x.psth)), axis=1)\n",
    "final_df = rust_data[-mask]\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d05f1df5-7a44-4e9a-9087-6ca53ca0e426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 384, 40)\n",
      "Nans remaining after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert psth to spike matrix\n",
    "final_spike_arr = np.array(list(final_df.psth))\n",
    "print(final_spike_arr.shape)\n",
    "\n",
    "# Check for remaining nan\n",
    "print(f'Nans remaining after removal: {np.isnan(final_spike_arr).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ef4ea59-3cb6-40f8-b7a7-65ebe8f71f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3747, 384)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create avg_spikes\n",
    "avg_spikes = np.mean(final_spike_arr, axis=2)\n",
    "avg_spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef7c165d-997b-4860-8476-cf62cb7edfa3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Objaverse pathlist\n",
    "locker_prefix = '/Volumes/'\n",
    "path_series = final_df['img_full_path'].str[16:].apply(lambda x : locker_prefix + x)\n",
    "natimg_path_list = path_series.tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0f6c2a8-9663-4e73-a411-d8253bd7a0a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2975"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elias Neptune pathlist with img_full_path (same as objaverse)\n",
    "locker_prefix = '/Volumes/'\n",
    "path_series = final_df['img_full_path'].str[16:].apply(lambda x : locker_prefix + x)\n",
    "natimg_path_list = path_series.tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58091f0c-b040-4e74-b6ee-19985db29621",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/qxlgfr6961b36tyhj2p5y0c00000gn/T/ipykernel_87861/3921630079.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['spliced_scenefile'] = final_df['scenefile'].str.removesuffix('.json').str[start_idx:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3747"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elias Neptune pathlist without img_full_path\n",
    "start_idx = 28\n",
    "final_df['spliced_scenefile'] = final_df['scenefile'].str.removesuffix('.json').str[start_idx:]\n",
    "\n",
    "# Generate img_full_path\n",
    "elias_neptune_prefix = '/Volumes/issa-locker/Data/West/Saved_Images/Saved_Images_West_neural_stim_EliasNeptune/Save_Images_West_EliasNeptune/'\n",
    "\n",
    "def png_path_end_int(path):\n",
    "    match = re.search(r'(\\d+)\\.png$', path)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Returns \"123\" as string\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for scenefile in final_df['spliced_scenefile'].unique():\n",
    "    sfile_path = elias_neptune_prefix + scenefile\n",
    "    img_list = os.listdir(sfile_path)\n",
    "    # Note: there is one .json in each scenefile, which is mapped to None in dict\n",
    "    idx_to_path = {png_path_end_int(img):'/'.join([sfile_path, img]) for img in img_list}\n",
    "    scene_mask = final_df['spliced_scenefile'] == scenefile\n",
    "    final_df.loc[scene_mask, 'img_full_path'] = final_df.loc[scene_mask, 'stim_idx'].map(idx_to_path) \n",
    "\n",
    "natimg_path_list = final_df['img_full_path'].tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff435887-b53a-4b3b-a52d-5571b03b98e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rust pathlist\n",
    "path_series = final_df['stim_idx'].apply(lambda x : \n",
    "                                           f'/Users/parsatalaie/Downloads/rust_natimgs/Nat300_{x+1}.png')\n",
    "natimg_path_list = path_series.tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228ffe4-a981-4a5d-a40b-e65af06513e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# HvM pathlist without img_full_path column\n",
    "\n",
    "# get spliced scenefile (for local pathing) (Check out warning if things go wrong...)\n",
    "start_idx = 28\n",
    "final_df['spliced_scenefile'] = final_df['scenefile'].str.removesuffix('.json').str[start_idx:]\n",
    "\n",
    "# Generate img_full_path\n",
    "hvm_prefix = '/Users/parsatalaie/Desktop/Marmoset Datasets/hvm10/'\n",
    "\n",
    "def png_path_end_int(path):\n",
    "    match = re.search(r'(\\d+)\\.png$', path)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Returns \"123\" as string\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for scenefile in final_df['spliced_scenefile'].unique():\n",
    "    sfile_path = hvm_prefix + scenefile\n",
    "    img_list = os.listdir(sfile_path)\n",
    "    # Note: there is one .json in each scenefile, which is mapped to None in dict\n",
    "    idx_to_path = {png_path_end_int(img):'/'.join([sfile_path, img]) for img in img_list}\n",
    "    scene_mask = final_df['spliced_scenefile'] == scenefile\n",
    "    final_df.loc[scene_mask, 'img_full_path'] = final_df.loc[scene_mask, 'stim_idx'].map(idx_to_path) \n",
    "\n",
    "natimg_path_list = final_df['img_full_path'].tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0916f-cbf3-4e1b-a3af-bc82e6fd8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Can use 57: + strip .png to double check that indices are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9c0aa2-db97-4d2f-a790-9c37a5c34472",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m51\u001b[39m\n\u001b[1;32m      3\u001b[0m alter_hvm_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m hvm_path : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/parsatalaie/Desktop/Marmoset Datasets/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m hvm_path[start_idx:]\n\u001b[0;32m----> 4\u001b[0m natimg_paths \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_full_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(alter_hvm_path)\n\u001b[1;32m      5\u001b[0m natimg_path_list \u001b[38;5;241m=\u001b[39m natimg_paths\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mlen\u001b[39m(natimg_path_list)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(hvm_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# HVM NATIMG_PATH_LIST\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m51\u001b[39m\n\u001b[0;32m----> 3\u001b[0m alter_hvm_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m hvm_path : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/parsatalaie/Desktop/Marmoset Datasets/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m hvm_path[start_idx:]\n\u001b[1;32m      4\u001b[0m natimg_paths \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_full_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(alter_hvm_path)\n\u001b[1;32m      5\u001b[0m natimg_path_list \u001b[38;5;241m=\u001b[39m natimg_paths\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# HvM pathlist using img_full_path\n",
    "start_idx = 51\n",
    "alter_hvm_path = lambda hvm_path : '/Users/parsatalaie/Desktop/Marmoset Datasets/' + hvm_path[start_idx:]\n",
    "natimg_paths = final_df['img_full_path'].apply(alter_hvm_path)\n",
    "natimg_path_list = natimg_paths.tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4d954d43-b123-4fba-9e7c-4a031239002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 3747)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose spikes to match formatting of old data\n",
    "avg_spikes = avg_spikes.transpose()\n",
    "avg_spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd0f05ca-7e66-45e9-a794-efec8e00d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save avg_spikes\n",
    "np.save(f'./{year}_{month}_{day}/marm_avg_spikes_{year}{month}{day}', avg_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cdfd1dc-2a08-42a7-be90-97f925c0d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle it\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(f'./{year}_{month}_{day}/natimg_path_list_{year}{month}{day}', 'wb') as fp:   #Pickling\n",
    "    pickle.dump(natimg_path_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ee91e-359f-4311-9ad6-95fae826dafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9a9b1-bfec-4f4a-aebc-e735c1031db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SHR\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "550fe2eb-0186-41ca-99ba-26c1138192f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "from collections import Counter\n",
    "\n",
    "marm_avg_spikes_t = avg_spikes\n",
    "marm_avg_spikes = zscore(np.transpose(marm_avg_spikes_t.astype('float32')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94212aeb-d84a-428c-a139-982e647a8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max_reps\n",
    "\n",
    "trial_counts = []\n",
    "\n",
    "for path in set(natimg_path_list):\n",
    "    trial_counts.append(natimg_path_list.count(path))\n",
    "\n",
    "max_reps = max(trial_counts)\n",
    "\n",
    "min_repeat = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90f93557-dab6-48ca-94d5-ef3de393743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data parameters\n",
    "ch_tot = marm_avg_spikes.shape[1]\n",
    "stim_tot = marm_avg_spikes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5ad5e5-df15-47eb-8865-848c7a34289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD SHR (HvM): Get demon matrix for each neuron\n",
    "\n",
    "many_path_list = [path for path in natimg_path_list \n",
    "                      if natimg_path_list.count(path) >= min_repeat]\n",
    "img_count = len(set(many_path_list))\n",
    "sh_data = np.zeros(ch_tot)\n",
    "img_spikes_tot = np.zeros((ch_tot, max_reps, img_count))\n",
    "\n",
    "for ch in range(ch_tot):\n",
    "    neuron = marm_avg_spikes[:, ch]\n",
    "    count_arr = np.zeros((max_reps, img_count))\n",
    "    count_arr[:] = np.nan\n",
    "    for i, path in enumerate(set(many_path_list)):\n",
    "        idx_list = [i for i, j in enumerate(natimg_path_list) if j == path]\n",
    "        # note: original mistake, ^ should take natimg_path_list as arg\n",
    "        for rep, idx in enumerate(idx_list):\n",
    "            count_arr[rep, i] = neuron[idx]\n",
    "    img_spikes_tot[ch] = count_arr\n",
    "    neuron_1, neuron_2 = count_arr[::2], count_arr[1::2]\n",
    "    neuron_1_avg = np.nanmean(neuron_1, axis=0)\n",
    "    neuron_2_avg = np.nanmean(neuron_2, axis=0)\n",
    "    sh, _ = stats.pearsonr(neuron_1_avg, neuron_2_avg)\n",
    "    sh_data[ch] = sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75ab9047-38cf-4523-95bd-10899288630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor SHR code:\n",
    "\n",
    "'''\n",
    "want to convert stim x ch --> ch x reps x image\n",
    "subproblem: convert stim --> rep x image\n",
    "'''\n",
    "\n",
    "def ch_shr(ch_data, path_list, min_repeats):\n",
    "    ''' Gets the split-halves reliability for a single channel\n",
    "\n",
    "    Args:\n",
    "        ch_data (n by 1 array): ordered channel activity\n",
    "        path_list: ordered image paths\n",
    "        min_repeats: minimum repetitions required for an image to be used\n",
    "\n",
    "    Returns:\n",
    "        shr: split-halves reliability\n",
    "        count_arr: matrix of repetitions x image for the channel\n",
    "    '''\n",
    "    # Convert ch_data --> reps x image using path_list\n",
    "\n",
    "    path_counts = Counter(path_list)\n",
    "    valid_paths = [path for path, count in path_counts.items() if count >= min_repeats]\n",
    "    unique_imgs = set(valid_paths)\n",
    "    img_count = len(unique_imgs)\n",
    "    max_reps = max(path_counts[path] for path in valid_paths)\n",
    "    count_arr = np.full((max_reps, img_count), np.nan)\n",
    "    for unique_img_idx, path in enumerate(unique_imgs):\n",
    "        idx_list = [i for i, j in enumerate(natimg_path_list) if j == path]\n",
    "        np.random.shuffle(idx_list) # NOTE RANDOMNESS INTRODUCED!\n",
    "        reps = len(idx_list)\n",
    "        count_arr[:reps, unique_img_idx] = ch_data[idx_list]\n",
    "    \n",
    "    # Find SHR using count_arr\n",
    "    neuron_1, neuron_2 = count_arr[::2], count_arr[1::2]\n",
    "    neuron_1_avg = np.nanmean(neuron_1, axis=0)\n",
    "    neuron_2_avg = np.nanmean(neuron_2, axis=0)\n",
    "    shr, _ = stats.pearsonr(neuron_1_avg, neuron_2_avg)\n",
    "\n",
    "    return shr, count_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39e268e4-4eac-4797-8087-ef37c2ed73b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "min_repeat = 2\n",
    "\n",
    "sh_data = np.zeros(ch_tot)\n",
    "unique_img_count = len(set(natimg_path_list))\n",
    "img_spikes_tot = np.zeros((ch_tot, max_reps, unique_img_count))\n",
    "shr_arr = np.zeros((folds, ch_tot))\n",
    "\n",
    "for fold in range(folds):\n",
    "    for ch in range(ch_tot):\n",
    "        shr, _ = ch_shr(marm_avg_spikes[:, ch], natimg_path_list, min_repeat)\n",
    "        shr_arr[fold, ch] = shr\n",
    "        print(ch)\n",
    "\n",
    "sh_data = np.mean(shr_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "579ad9d3-f1c4-4899-a180-dbb4c7491580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good neurons: 171\n"
     ]
    }
   ],
   "source": [
    "sh_limit = .3\n",
    "\n",
    "# Get good idx\n",
    "good_idx = np.where(sh_data >= sh_limit)[0]\n",
    "\n",
    "# get good sh, exp\n",
    "good_sh = sh_data[good_idx]\n",
    "\n",
    "good_ch_tot = good_idx.shape[0]\n",
    "\n",
    "print(f'Number of good neurons: {good_ch_tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b350125-b160-48ce-ad96-3b76a4aed0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SHR Data\n",
    "\n",
    "imageset = 'Rust'\n",
    "\n",
    "np.save(f'./{year}_{month}_{day}/{imageset}_SHR_data_{year}{month}{day}', sh_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1187e019-eb61-4fd0-a475-b65e6777476f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e7ff0-e5dc-4886-aee8-591d6bf5b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check if issue is filtering of df: start with all trials\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c51b498-46d2-4227-8a63-e60a7c975d0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching trial parameters...\n",
      "... done (0.02410578727722168 sec).\n",
      "Pre-fetching PSTHs from HDF5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tables/attributeset.py:290: DataTypeWarning: Unsupported type for attribute 'scenefile_by_stim_mat' in node '/'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done.\n",
      "Duration=0.01466134786605835 minutes\n",
      "Fancy slicing numpy array...\n",
      "... done.\n",
      "Duration=0.01987988551457723 minutes\n"
     ]
    }
   ],
   "source": [
    "# h5_2_df the whole file (same time_window)\n",
    "\n",
    "time_window = [start_bin, end_bin]\n",
    "all_data = h5_2_df(pathname, time_window=time_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d392b131-d5b5-414c-b34a-5fd69f7e76e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3364, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply masks\n",
    "\n",
    "nan_mask = all_data.apply(lambda x : np.all(np.isnan(x.psth)), axis=1)\n",
    "fix_all_data = all_data[-nan_mask]\n",
    "scenefile_mask = fix_all_data['scenefile'] == '/mkturkfiles/scenebags/West/20231025_Rust_NaturalImages300_300ms.json'\n",
    "final_all_data = fix_all_data[scenefile_mask]\n",
    "final_all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1244092-bcde-4b9f-a70f-57d9d7452fe3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3364, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3364"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert psth to spike matrix\n",
    "final_spike_arr = np.array(list(final_all_data.psth))\n",
    "final_spike_arr.shape\n",
    "\n",
    "# Check for remaining nan\n",
    "np.isnan(final_spike_arr).sum()\n",
    "\n",
    "# Create avg_spikes\n",
    "avg_spikes = np.mean(final_spike_arr, axis=2)\n",
    "print(avg_spikes.shape)\n",
    "\n",
    "# Create natimg_path_list\n",
    "path_series = final_all_data['stim_idx'].apply(lambda x : \n",
    "                                           f'/Users/parsatalaie/Downloads/rust_natimgs/Nat300_{x+1}.png')\n",
    "natimg_path_list = path_series.tolist()\n",
    "len(natimg_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "241be953-397a-4c6b-b407-e5fe44ce96b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if equivalent\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_frame_equal(final_all_data\u001b[38;5;241m.\u001b[39msort_index(), final_df)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrames are identical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if equivalent\n",
    "\n",
    "try:\n",
    "    pd.testing.assert_frame_equal(final_all_data.sort_index(), final_df)\n",
    "    print(\"DataFrames are identical\")\n",
    "except AssertionError:\n",
    "    print(\"DataFrames are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a786-01f2-4b91-845b-3e1f34452ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa6c39-4fe1-480f-87ec-2cd875ba218a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68713acd-63a4-477e-822e-0db5ef5edcd2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tables/attributeset.py:290: DataTypeWarning: Unsupported type for attribute 'scenefile_by_stim_mat' in node '/'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/tables/attributeset.py:290: DataTypeWarning: Unsupported type for attribute 'scenefile_by_stim_mat' in node '/'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    }
   ],
   "source": [
    "# Dan new ch_depth\n",
    "zero_coords = pd.read_hdf(pathname, 'zero_coordinates')\n",
    "imro_tbl = pd.read_hdf(pathname, 'imro_table')\n",
    "\n",
    "zero_coords['monkey'] = monkey\n",
    "zero_coords['date'] = f'{year}{month}{day}'\n",
    "imro_tbl['monkey'] = monkey\n",
    "imro_tbl['date'] = f'{year}{month}{day}'\n",
    "\n",
    "imro_tbl['ch_idx_glx'] = imro_tbl.index\n",
    "\n",
    "chs_meta_df = chs_meta_2_site_coords(zero_coords, imro_tbl)\n",
    "\n",
    "ch_depths = np.array(chs_meta_df['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0120182d-fc6b-486e-beae-e3f46e1fbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ch_depths\n",
    "\n",
    "np.save(f'./{year}_{month}_{day}/ch_depth_{year}{month}{day}', ch_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b305ca-efbe-4d41-aeab-d0364e8cbd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49a1fa-21c5-4147-90a0-8e78da45a3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d57ea05b-a5bd-49a1-9b98-3c73a5870532",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'site_coordinates' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create new_ch_depth\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m coords \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_coordinates\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m depth_ch_idx \u001b[38;5;241m=\u001b[39m coords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxis1\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n\u001b[1;32m      6\u001b[0m new_ch_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m384\u001b[39m))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m h5o\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e(name), lapl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lapl)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'site_coordinates' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "# Create new_ch_depth\n",
    "\n",
    "coords = f['site_coordinates']\n",
    "depth_ch_idx = coords['axis1'][:]\n",
    "\n",
    "new_ch_depth = np.zeros((384))\n",
    "\n",
    "for i in range(384):\n",
    "    idx = depth_ch_idx[i]\n",
    "    new_ch_depth[i] = coords['block0_values'][:][:, 3][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "250f5228-cdf0-4ceb-a1f8-a17ccdab768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save list of ch depths\n",
    "\n",
    "np.save(f'./{year}_{month}_{day}/ch_depth_{year}{month}{day}', new_ch_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
